{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mybenkhadda/docxchain/blob/main/docxchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JEi_TqGvyFq",
        "outputId": "9f84608b-ef60-4dd2-ea97-1808707d2710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'docxchain'...\n",
            "remote: Enumerating objects: 403, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 403 (delta 6), reused 7 (delta 0), pack-reused 364\u001b[K\n",
            "Receiving objects: 100% (403/403), 253.25 MiB | 14.04 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n",
            "Updating files: 100% (342/342), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mybenkhadda/docxchain.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9BsbGJlwPy7",
        "outputId": "9a7ce096-b187-4200-e102-808733d83059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/docxchain\n"
          ]
        }
      ],
      "source": [
        "%cd docxchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m1ScrFUNwmqf"
      },
      "outputs": [],
      "source": [
        "! pip install -q pdf2image ipdb modelscope datasets==2.18.0 rapid_latex_ocr pyclipper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4U_D5bjzAw6",
        "outputId": "3389bc39-347a-4462-d38e-4bfe6d5a9a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow<=2.10 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (1.62.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (3.9.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (24.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (2.10.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (0.36.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<=2.10) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<=2.10) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow<=2.10) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<=2.10) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade \"tensorflow<=2.10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcbbR_EB0giD",
        "outputId": "b8ba04ed-bea3-4a7c-b470-be5f12e708b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.3 [186 kB]\n",
            "Fetched 186 kB in 1s (133 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Gnhh2vEUtgj0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import datetime\n",
        "import random\n",
        "import time\n",
        "import pytz\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pipelines.document_structurization import DocumentStructurization\n",
        "from utilities.visualization import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1HhZmKTXtgj1"
      },
      "outputs": [],
      "source": [
        "configs = dict()\n",
        "\n",
        "layout_analysis_configs = dict()\n",
        "layout_analysis_configs['from_modelscope_flag'] = False\n",
        "layout_analysis_configs['model_path'] = './home/DocXLayout_231012.pth'  # note that: currently the layout analysis model is NOT from modelscope\n",
        "configs['layout_analysis_configs'] = layout_analysis_configs\n",
        "\n",
        "text_detection_configs = dict()\n",
        "text_detection_configs['from_modelscope_flag'] = True\n",
        "text_detection_configs['model_path'] = 'damo/cv_resnet18_ocr-detection-line-level_damo'\n",
        "configs['text_detection_configs'] = text_detection_configs\n",
        "\n",
        "text_recognition_configs = dict()\n",
        "text_recognition_configs['from_modelscope_flag'] = True\n",
        "text_recognition_configs['model_path'] = 'damo/cv_convnextTiny_ocr-recognition-document_damo'  # alternatives: 'damo/cv_convnextTiny_ocr-recognition-scene_damo', 'damo/cv_convnextTiny_ocr-recognition-general_damo', 'damo/cv_convnextTiny_ocr-recognition-handwritten_damo'\n",
        "configs['text_recognition_configs'] = text_recognition_configs\n",
        "\n",
        "formula_recognition_configs = dict()\n",
        "formula_recognition_configs['from_modelscope_flag'] = False\n",
        "formula_recognition_configs['image_resizer_path'] = '/home/LaTeX-OCR_image_resizer.onnx'\n",
        "formula_recognition_configs['encoder_path'] = '/home/LaTeX-OCR_encoder.onnx'\n",
        "formula_recognition_configs['decoder_path'] = '/home/LaTeX-OCR_decoder.onnx'\n",
        "formula_recognition_configs['tokenizer_json'] = '/home/LaTeX-OCR_tokenizer.json'\n",
        "configs['formula_recognition_configs'] = formula_recognition_configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4D_4Yl6wn3Av"
      },
      "outputs": [],
      "source": [
        "random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5G74gldtgj1",
        "outputId": "9c34a8e8-3756-4216-c3b1-707b1a5eb9df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fix size testing.\n",
            "training chunk_sizes: [32]\n",
            "The output will be saved to  /content/docxchain/../../exp/ctdet_subfield/default\n",
            "heads {'hm': 11, 'cls': 4, 'ftype': 3, 'wh': 8, 'hm_sub': 2, 'wh_sub': 8, 'reg': 2, 'reg_sub': 2}\n",
            "[0]\n",
            "--> loading model from local file: ./home/DocXLayout_231012.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-25 07:37:38,645 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
            "Downloading: 100%|██████████| 312M/312M [00:13<00:00, 24.5MB/s]\n",
            "Downloading: 100%|██████████| 41.7k/41.7k [00:00<00:00, 249kB/s]\n",
            "Downloading: 100%|██████████| 8.06M/8.06M [00:00<00:00, 11.2MB/s]\n",
            "Downloading: 0.00B [00:00, ?B/s]\n",
            "Downloading: 100%|██████████| 118/118 [00:00<00:00, 183kB/s]\n",
            "Downloading: 100%|██████████| 61.7k/61.7k [00:00<00:00, 339kB/s]\n",
            "Downloading: 100%|██████████| 313k/313k [00:00<00:00, 960kB/s]\n",
            "Downloading: 100%|██████████| 436k/436k [00:00<00:00, 1.04MB/s]\n",
            "Downloading: 100%|██████████| 24.0/24.0 [00:00<00:00, 86.9kB/s]\n",
            "Downloading: 100%|██████████| 3.93k/3.93k [00:00<00:00, 2.63MB/s]\n",
            "2024-04-25 07:38:03,542 - modelscope - INFO - initiate model from /root/.cache/modelscope/hub/damo/cv_resnet18_ocr-detection-line-level_damo\n",
            "2024-04-25 07:38:03,544 - modelscope - INFO - initiate model from location /root/.cache/modelscope/hub/damo/cv_resnet18_ocr-detection-line-level_damo.\n",
            "2024-04-25 07:38:03,551 - modelscope - WARNING - No preprocessor field found in cfg.\n",
            "2024-04-25 07:38:03,552 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
            "2024-04-25 07:38:03,555 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/root/.cache/modelscope/hub/damo/cv_resnet18_ocr-detection-line-level_damo'}. trying to build by task and model information.\n",
            "2024-04-25 07:38:03,557 - modelscope - WARNING - Find task: ocr-detection, model type: None. Insufficient information to build preprocessor, skip building preprocessor\n",
            "2024-04-25 07:38:03,561 - modelscope - INFO - loading model from dir /root/.cache/modelscope/hub/damo/cv_resnet18_ocr-detection-line-level_damo\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/modelscope/utils/device.py:60: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/modelscope/pipelines/cv/ocr_utils/ops.py:744: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "2024-04-25 07:38:06,315 - modelscope - INFO - loading model from /root/.cache/modelscope/hub/damo/cv_resnet18_ocr-detection-line-level_damo/tf_ckpts/checkpoint-80000\n",
            "2024-04-25 07:38:08,005 - modelscope - WARNING - Model revision not specified, use revision: v2.4.0\n",
            "Downloading: 100%|██████████| 1.51k/1.51k [00:00<00:00, 597kB/s]\n",
            "Downloading: 100%|██████████| 100k/100k [00:00<00:00, 402kB/s]\n",
            "Downloading: 100%|██████████| 73.3M/73.3M [00:02<00:00, 25.7MB/s]\n",
            "Downloading: 100%|██████████| 73.3M/73.3M [00:02<00:00, 27.8MB/s]\n",
            "Downloading: 100%|██████████| 5.14k/5.14k [00:00<00:00, 6.41MB/s]\n",
            "Downloading: 100%|██████████| 8.85k/8.85k [00:00<00:00, 10.3MB/s]\n",
            "Downloading: 100%|██████████| 52.0k/52.0k [00:00<00:00, 329kB/s]\n",
            "Downloading: 100%|██████████| 29.6k/29.6k [00:00<00:00, 371kB/s]\n",
            "2024-04-25 07:38:20,872 - modelscope - INFO - initiate model from /root/.cache/modelscope/hub/damo/cv_convnextTiny_ocr-recognition-document_damo\n",
            "2024-04-25 07:38:20,874 - modelscope - INFO - initiate model from location /root/.cache/modelscope/hub/damo/cv_convnextTiny_ocr-recognition-document_damo.\n",
            "2024-04-25 07:38:20,876 - modelscope - INFO - initialize model from /root/.cache/modelscope/hub/damo/cv_convnextTiny_ocr-recognition-document_damo\n",
            "2024-04-25 07:38:21,195 - modelscope - INFO - loading model from dir /root/.cache/modelscope/hub/damo/cv_convnextTiny_ocr-recognition-document_damo\n",
            "2024-04-25 07:38:21,235 - modelscope - INFO - loading model done\n"
          ]
        }
      ],
      "source": [
        "document_structurizer = DocumentStructurization(configs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wbGwLg3_tgj2"
      },
      "outputs": [],
      "source": [
        "def pdf2image(pdf_path):\n",
        "    \"\"\"\n",
        "    Convert a PDF file to an image.\n",
        "    \"\"\"\n",
        "    images = convert_from_path(pdf_path)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "\n",
        "        images[i] = np.array(images[i])\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "F13oEt7mtgj2"
      },
      "outputs": [],
      "source": [
        "def extractFooter(image):\n",
        "    image = image[:2200,:, :]\n",
        "    fotter = image[2200:,:, :]\n",
        "    return image, fotter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "UxnWV95dtgj2"
      },
      "outputs": [],
      "source": [
        "def merge_regions(results):\n",
        "    regions = []\n",
        "    for page in range(len(results) - 1):\n",
        "        if results[page][\"information\"][-1][\"category_name\"] == results[page+1][\"information\"][0][\"category_name\"]:\n",
        "            if results[page][\"information\"][-1][\"category_name\"] == \"table\":\n",
        "                regions.append({\n",
        "                    \"page\": page,\n",
        "                    \"region_poly1\": results[page][\"information\"][-1][\"region_poly\"],\n",
        "                    \"region_poly2\": results[page+1][\"information\"][0][\"region_poly\"],\n",
        "                })\n",
        "                results[page][\"information\"][-1] = {}\n",
        "                results[page+1][\"information\"][0] = {}\n",
        "\n",
        "    return results, regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ouU2rhYvtgj2"
      },
      "outputs": [],
      "source": [
        "def order_file(results):\n",
        "    results.sort(key=lambda x: (x[\"region_poly\"][1]))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "OPfQCTPktgj2"
      },
      "outputs": [],
      "source": [
        "def structure1image(image):\n",
        "\n",
        "    final_result = document_structurizer(image)\n",
        "\n",
        "    final_result = order_file(final_result)\n",
        "\n",
        "    document_structurization_visualization(final_result, image)\n",
        "\n",
        "    return final_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5xwSxEYFtgj2"
      },
      "outputs": [],
      "source": [
        "def document_structure(path):\n",
        "    images = pdf2image(path)\n",
        "    images = [extractFooter(image)[0] for image in images]\n",
        "\n",
        "    doc = [\n",
        "        {\n",
        "            \"page\": 0,\n",
        "            \"content\": structure1image(images[0])\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    if len(images) > 1:\n",
        "        for i in range(1, len(images)):\n",
        "            tmp = structure1image(images[i])\n",
        "            if doc[i-1][\"content\"][-1][\"category_name\"] == tmp[0][\"category_name\"] and doc[i-1][\"content\"][-1][\"category_name\"] == \"table\":\n",
        "                img1 = images[i-1][doc[i-1][\"content\"][-1][\"region_poly\"][1]:doc[i-1][\"content\"][-1][\"region_poly\"][-1],:,:]\n",
        "                img2 = images[i][tmp[0][\"region_poly\"][1]:tmp[0][\"region_poly\"][-1],:,:]\n",
        "\n",
        "                concatenated_img = np.concatenate((img1, img2), axis=0)\n",
        "\n",
        "                plt.imsave(f\"tables/table-{random.randint(0,100)}-page{i}.jpg\", concatenated_img)\n",
        "\n",
        "                # plt.imshow(concatenated_img)\n",
        "\n",
        "                # result_merge = structure1image(concatenated_img)\n",
        "\n",
        "                doc[i-1][\"content\"] = doc[i-1][\"content\"][:-2]\n",
        "\n",
        "\n",
        "\n",
        "                doc.append(\n",
        "                    {\n",
        "                        \"page\": i,\n",
        "                        \"content\": structure1image(images[i])[1:]\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                doc.append({\n",
        "                    \"page\": i,\n",
        "                    \"content\": structure1image(images[i])\n",
        "                })\n",
        "\n",
        "    return(doc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "7YI4mUD4tgj2",
        "outputId": "69e9fb8b-ebe8-4ab9-9f63-60d4189e8f4d"
      },
      "outputs": [],
      "source": [
        "output = document_structure(\"purchasing_contract_example.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "beMJxZ6H1htB"
      },
      "outputs": [],
      "source": [
        "def json2df(jsonData):\n",
        "  # try:\n",
        "    data = []\n",
        "    for i in range(len(jsonData)):\n",
        "      page = jsonData[i][\"content\"]\n",
        "      for j in range(len(page)):\n",
        "        region_poly = page[j][\"region_poly\"]\n",
        "        category_name = page[j][\"category_name\"]\n",
        "        content = \" \".join([page[j][\"text_list\"][k][\"content\"][0] for k in range(len(page[j][\"text_list\"]))])\n",
        "        page_number = i\n",
        "        data.append(\n",
        "            {\n",
        "                \"region\": region_poly,\n",
        "                \"category_name\": category_name,\n",
        "                \"content\": content,\n",
        "                \"page\": int(page_number)\n",
        "            }\n",
        "        )\n",
        "    return pd.DataFrame(data, columns = data[0].keys())\n",
        "  # except:\n",
        "  #   print(page[j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "uxLhNznx2vAV"
      },
      "outputs": [],
      "source": [
        "df = json2df(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "zUJ06B1j21tn"
      },
      "outputs": [],
      "source": [
        "def extractTables(pdf, df):\n",
        "  images = pdf2image(pdf)\n",
        "  tables = df[df[\"category_name\"] == \"table\"]\n",
        "  for i in range(tables.shape[0]):\n",
        "    region = tables.iloc[0][\"region\"]\n",
        "    page = tables.iloc[0][\"page\"]\n",
        "    img = images[page][region[1]:region[3], region[2]:region[6],:]\n",
        "    plt.imsave(f\"tables/table-{random.randint(0,100)}-page{tables.iloc[0]['page']}.jpg\", img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "zI51CpumQqL6",
        "outputId": "793c60dc-578b-4fb5-b93c-51a81180a8b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "cannot write empty image as JPEG",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-685efabfae0e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextractTables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"purchasing_contract_example.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-c8ac255bd397>\u001b[0m in \u001b[0;36mextractTables\u001b[0;34m(pdf, df)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mregion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"region\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"page\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tables/table-{random.randint(0,100)}-page{tables.iloc[0]['page']}.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot write empty image as JPEG\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot write empty image as JPEG"
          ]
        }
      ],
      "source": [
        "extractTables(\"purchasing_contract_example.pdf\", df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rc2Ms84Wx97"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
