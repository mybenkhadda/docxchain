{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Init environnement ⚙","metadata":{"id":"wwUkqrfgqVPO"}},{"cell_type":"code","source":"!git clone https://github.com/mybenkhadda/docxchain.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQTBA0FJqLMv","outputId":"c5eb5fc7-8ed6-4399-89f3-6fe754695801","execution":{"iopub.status.busy":"2024-05-21T07:41:27.637809Z","iopub.execute_input":"2024-05-21T07:41:27.638162Z","iopub.status.idle":"2024-05-21T07:41:37.431717Z","shell.execute_reply.started":"2024-05-21T07:41:27.638133Z","shell.execute_reply":"2024-05-21T07:41:37.430705Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'docxchain'...\nremote: Enumerating objects: 637, done.\u001b[K\nremote: Counting objects: 100% (273/273), done.\u001b[K\nremote: Compressing objects: 100% (220/220), done.\u001b[K\nremote: Total 637 (delta 105), reused 158 (delta 43), pack-reused 364\u001b[K\nReceiving objects: 100% (637/637), 257.14 MiB | 38.51 MiB/s, done.\nResolving deltas: 100% (160/160), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd docxchain/docxchain","metadata":{"id":"dwFiuUjbqLMx","outputId":"09118286-79d1-4389-da42-f43f80ae07b5","execution":{"iopub.status.busy":"2024-05-21T07:41:42.562458Z","iopub.execute_input":"2024-05-21T07:41:42.563309Z","iopub.status.idle":"2024-05-21T07:41:42.569663Z","shell.execute_reply.started":"2024-05-21T07:41:42.563266Z","shell.execute_reply":"2024-05-21T07:41:42.568703Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/docxchain/docxchain\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install -q pdf2image ipdb modelscope datasets==2.18.0 rapid_latex_ocr pyclipper tf_slim langchain chromadb","metadata":{"id":"AIICn8Clrodk","execution":{"iopub.status.busy":"2024-05-21T09:07:55.944751Z","iopub.execute_input":"2024-05-21T09:07:55.945190Z","iopub.status.idle":"2024-05-21T09:08:31.423660Z","shell.execute_reply.started":"2024-05-21T09:07:55.945157Z","shell.execute_reply":"2024-05-21T09:08:31.422457Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.10.0 which is incompatible.\ntensorflow-serving-api 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-serving-api 2.14.1 requires tensorflow<3,>=2.14.1, but you have tensorflow 2.10.0 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.10.0 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade \"tensorflow<=2.10\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-1dl1Z6Jrx9v","outputId":"ee501323-49c6-47a9-a8c9-401682df76fc","execution":{"iopub.status.busy":"2024-05-21T07:42:19.770624Z","iopub.execute_input":"2024-05-21T07:42:19.771042Z","iopub.status.idle":"2024-05-21T07:43:21.282623Z","shell.execute_reply.started":"2024-05-21T07:42:19.771009Z","shell.execute_reply":"2024-05-21T07:43:21.281175Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting tensorflow<=2.10\n  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (23.5.26)\nCollecting gast<=0.4.0,>=0.2.1 (from tensorflow<=2.10)\n  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (3.10.0)\nCollecting keras<2.11,>=2.10.0 (from tensorflow<=2.10)\n  Downloading keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras-preprocessing>=1.1.1 (from tensorflow<=2.10)\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (16.0.6)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (23.2)\nCollecting protobuf<3.20,>=3.9.2 (from tensorflow<=2.10)\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (1.16.0)\nCollecting tensorboard<2.11,>=2.10 (from tensorflow<=2.10)\n  Downloading tensorboard-2.10.1-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (0.35.0)\nCollecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow<=2.10)\n  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (4.9.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<=2.10) (1.14.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<=2.10) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (2.26.1)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow<=2.10)\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (2.31.0)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow<=2.10)\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.11,>=2.10->tensorflow<=2.10)\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10) (3.0.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<=2.10) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow<=2.10) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<=2.10) (3.2.2)\nDownloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nDownloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, keras, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow\n  Attempting uninstall: keras\n    Found existing installation: keras 3.2.1\n    Uninstalling keras-3.2.1:\n      Successfully uninstalled keras-3.2.1\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.15.0\n    Uninstalling tensorflow-estimator-2.15.0:\n      Successfully uninstalled tensorflow-estimator-2.15.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: gast\n    Found existing installation: gast 0.5.4\n    Uninstalling gast-0.5.4:\n      Successfully uninstalled gast-0.5.4\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.19.6 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\ngoogle-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nonnx 1.16.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ntensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.10.0 which is incompatible.\ntensorflow-serving-api 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-serving-api 2.14.1 requires tensorflow<3,>=2.14.1, but you have tensorflow 2.10.0 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.10.0 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.10.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:18:20.856778Z","iopub.execute_input":"2024-05-21T08:18:20.857218Z","iopub.status.idle":"2024-05-21T08:18:34.130236Z","shell.execute_reply.started":"2024-05-21T08:18:20.857185Z","shell.execute_reply":"2024-05-21T08:18:34.129047Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!apt-get install poppler-utils -y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vos31jakr5lO","outputId":"e4588c8f-c4ec-45fe-8791-7994b81ee939","execution":{"iopub.status.busy":"2024-05-21T07:43:21.285140Z","iopub.execute_input":"2024-05-21T07:43:21.285570Z","iopub.status.idle":"2024-05-21T07:43:32.719690Z","shell.execute_reply.started":"2024-05-21T07:43:21.285527Z","shell.execute_reply":"2024-05-21T07:43:32.718691Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libpoppler97 poppler-data\nSuggested packages:\n  ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\n  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n  fonts-arphic-uming fonts-nanum\nThe following NEW packages will be installed:\n  libpoppler97 poppler-data poppler-utils\n0 upgraded, 3 newly installed, 0 to remove and 65 not upgraded.\nNeed to get 2564 kB of archives.\nAfter this operation, 16.8 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/main amd64 poppler-data all 0.4.9-2 [1475 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpoppler97 amd64 0.86.1-0ubuntu1.4 [916 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 poppler-utils amd64 0.86.1-0ubuntu1.4 [174 kB]\nFetched 2564 kB in 1s (3599 kB/s)       \nSelecting previously unselected package poppler-data.\n(Reading database ... 113807 files and directories currently installed.)\nPreparing to unpack .../poppler-data_0.4.9-2_all.deb ...\nUnpacking poppler-data (0.4.9-2) ...\nSelecting previously unselected package libpoppler97:amd64.\nPreparing to unpack .../libpoppler97_0.86.1-0ubuntu1.4_amd64.deb ...\nUnpacking libpoppler97:amd64 (0.86.1-0ubuntu1.4) ...\nSelecting previously unselected package poppler-utils.\nPreparing to unpack .../poppler-utils_0.86.1-0ubuntu1.4_amd64.deb ...\nUnpacking poppler-utils (0.86.1-0ubuntu1.4) ...\nSetting up libpoppler97:amd64 (0.86.1-0ubuntu1.4) ...\nSetting up poppler-data (0.4.9-2) ...\nSetting up poppler-utils (0.86.1-0ubuntu1.4) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for fontconfig (2.13.1-2ubuntu3) ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir home\n\n!wget https://zenodo.org/records/11191655/files/DocXLayout_231012.pth -P home\n!wget https://zenodo.org/records/11191655/files/LaTeX-OCR_decoder.onnx -P home\n!wget https://zenodo.org/records/11191655/files/LaTeX-OCR_encoder.onnx -P home\n!wget https://zenodo.org/records/11191655/files/LaTeX-OCR_image_resizer.onnx -P home\n!wget https://zenodo.org/records/11191655/files/LaTeX-OCR_tokenizer.json -P home","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:00:13.792863Z","iopub.execute_input":"2024-05-21T08:00:13.793695Z","iopub.status.idle":"2024-05-21T08:03:53.032447Z","shell.execute_reply.started":"2024-05-21T08:00:13.793655Z","shell.execute_reply":"2024-05-21T08:03:53.031515Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"--2024-05-21 08:00:15--  https://zenodo.org/records/11191655/files/DocXLayout_231012.pth\nResolving zenodo.org (zenodo.org)... 188.184.103.159, 188.184.98.238, 188.185.79.172, ...\nConnecting to zenodo.org (zenodo.org)|188.184.103.159|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 77013789 (73M) [application/octet-stream]\nSaving to: 'home/DocXLayout_231012.pth'\n\nDocXLayout_231012.p 100%[===================>]  73.45M   840KB/s    in 1m 52s  \n\n2024-05-21 08:02:08 (671 KB/s) - 'home/DocXLayout_231012.pth' saved [77013789/77013789]\n\n--2024-05-21 08:02:09--  https://zenodo.org/records/11191655/files/LaTeX-OCR_decoder.onnx\nResolving zenodo.org (zenodo.org)... 188.184.98.238, 188.185.79.172, 188.184.103.159, ...\nConnecting to zenodo.org (zenodo.org)|188.184.98.238|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 50952726 (49M) [application/octet-stream]\nSaving to: 'home/LaTeX-OCR_decoder.onnx'\n\nLaTeX-OCR_decoder.o 100%[===================>]  48.59M  4.70MB/s    in 15s     \n\n2024-05-21 08:02:24 (3.32 MB/s) - 'home/LaTeX-OCR_decoder.onnx' saved [50952726/50952726]\n\n--2024-05-21 08:02:25--  https://zenodo.org/records/11191655/files/LaTeX-OCR_encoder.onnx\nResolving zenodo.org (zenodo.org)... 188.184.98.238, 188.185.79.172, 188.184.103.159, ...\nConnecting to zenodo.org (zenodo.org)|188.184.98.238|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 89008136 (85M) [application/octet-stream]\nSaving to: 'home/LaTeX-OCR_encoder.onnx'\n\nLaTeX-OCR_encoder.o 100%[===================>]  84.88M  13.2MB/s    in 14s     \n\n2024-05-21 08:02:40 (6.14 MB/s) - 'home/LaTeX-OCR_encoder.onnx' saved [89008136/89008136]\n\n--2024-05-21 08:02:41--  https://zenodo.org/records/11191655/files/LaTeX-OCR_image_resizer.onnx\nResolving zenodo.org (zenodo.org)... 188.184.98.238, 188.185.79.172, 188.184.103.159, ...\nConnecting to zenodo.org (zenodo.org)|188.184.98.238|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 38967751 (37M) [application/octet-stream]\nSaving to: 'home/LaTeX-OCR_image_resizer.onnx'\n\nLaTeX-OCR_image_res 100%[===================>]  37.16M   613KB/s    in 68s     \n\n2024-05-21 08:03:51 (561 KB/s) - 'home/LaTeX-OCR_image_resizer.onnx' saved [38967751/38967751]\n\n--2024-05-21 08:03:51--  https://zenodo.org/records/11191655/files/LaTeX-OCR_tokenizer.json\nResolving zenodo.org (zenodo.org)... 188.184.98.238, 188.184.103.159, 188.185.79.172, ...\nConnecting to zenodo.org (zenodo.org)|188.184.98.238|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 24174 (24K) [text/plain]\nSaving to: 'home/LaTeX-OCR_tokenizer.json'\n\nLaTeX-OCR_tokenizer 100%[===================>]  23.61K   150KB/s    in 0.2s    \n\n2024-05-21 08:03:52 (150 KB/s) - 'home/LaTeX-OCR_tokenizer.json' saved [24174/24174]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Challenge 1: Parsing 🔎","metadata":{"id":"zj6Omlo0t2SX"}},{"cell_type":"code","source":"import docxchain_po\nimport pandas as pd","metadata":{"id":"I_DecLmTqLMx","execution":{"iopub.status.busy":"2024-05-21T08:15:46.330023Z","iopub.execute_input":"2024-05-21T08:15:46.330796Z","iopub.status.idle":"2024-05-21T08:15:46.334799Z","shell.execute_reply.started":"2024-05-21T08:15:46.330762Z","shell.execute_reply":"2024-05-21T08:15:46.333907Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"d = docxchain_po.DocxChain_PO()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yqy32GDIqLMy","outputId":"3cf85df1-602e-46d2-a7cd-ab1991533af1","execution":{"iopub.status.busy":"2024-05-21T08:04:16.454752Z","iopub.execute_input":"2024-05-21T08:04:16.455765Z","iopub.status.idle":"2024-05-21T08:04:46.754009Z","shell.execute_reply.started":"2024-05-21T08:04:16.455720Z","shell.execute_reply":"2024-05-21T08:04:46.753090Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Fix size testing.\ntraining chunk_sizes: [32]\nThe output will be saved to  /kaggle/working/docxchain/docxchain/../../exp/ctdet_subfield/default\nheads {'hm': 11, 'cls': 4, 'ftype': 3, 'wh': 8, 'hm_sub': 2, 'wh_sub': 8, 'reg': 2, 'reg_sub': 2}\n[0]\n--> loading model from local file: home/DocXLayout_231012.pth\n","output_type":"stream"},{"name":"stderr","text":"2024-05-21 08:04:18,707 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\nDownloading: 100%|██████████| 312M/312M [00:02<00:00, 152MB/s]  \nDownloading: 100%|██████████| 41.7k/41.7k [00:00<00:00, 1.27MB/s]\nDownloading: 100%|██████████| 8.06M/8.06M [00:00<00:00, 40.4MB/s]\nDownloading: 0.00B [00:00, ?B/s]\nDownloading: 100%|██████████| 118/118 [00:00<00:00, 397kB/s]\nDownloading: 100%|██████████| 61.7k/61.7k [00:00<00:00, 1.68MB/s]\nDownloading: 100%|██████████| 313k/313k [00:00<00:00, 4.32MB/s]\nDownloading: 100%|██████████| 436k/436k [00:00<00:00, 4.06MB/s]\nDownloading: 100%|██████████| 24.0/24.0 [00:00<00:00, 123kB/s]\nDownloading: 100%|██████████| 3.93k/3.93k [00:00<00:00, 7.21MB/s]\n2024-05-21 08:04:29.863702: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl7strings6StrCatB5cxx11ERKNS0_8AlphaNumES3_']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN4absl12lts_202301258StatusOrIN3tsl4core11RefCountPtrIS1_EEEEvEE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n2024-05-21 08:04:32,905 - modelscope - INFO - initiate model from /root/.cache/modelscope/hub/damo/cv_resnet18_ocr-detection-line-level_damo\n2024-05-21 08:04:32,906 - modelscope - INFO - initiate model from location /root/.cache/modelscope/hub/damo/cv_resnet18_ocr-detection-line-level_damo.\n2024-05-21 08:04:32,911 - modelscope - WARNING - No preprocessor field found in cfg.\n2024-05-21 08:04:32,912 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n2024-05-21 08:04:32,912 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/root/.cache/modelscope/hub/damo/cv_resnet18_ocr-detection-line-level_damo'}. trying to build by task and model information.\n2024-05-21 08:04:32,913 - modelscope - WARNING - Find task: ocr-detection, model type: None. Insufficient information to build preprocessor, skip building preprocessor\n2024-05-21 08:04:32,915 - modelscope - INFO - loading model from dir /root/.cache/modelscope/hub/damo/cv_resnet18_ocr-detection-line-level_damo\n/opt/conda/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n  warnings.warn('`layer.apply` is deprecated and '\n2024-05-21 08:04:35,442 - modelscope - INFO - loading model from /root/.cache/modelscope/hub/damo/cv_resnet18_ocr-detection-line-level_damo/tf_ckpts/checkpoint-80000\n2024-05-21 08:04:37,811 - modelscope - WARNING - Model revision not specified, use revision: v2.4.0\nDownloading: 100%|██████████| 1.51k/1.51k [00:00<00:00, 5.30MB/s]\nDownloading: 100%|██████████| 100k/100k [00:00<00:00, 1.98MB/s]\nDownloading: 100%|██████████| 73.3M/73.3M [00:00<00:00, 124MB/s] \nDownloading: 100%|██████████| 73.3M/73.3M [00:00<00:00, 132MB/s] \nDownloading: 100%|██████████| 5.14k/5.14k [00:00<00:00, 7.81MB/s]\nDownloading: 100%|██████████| 8.85k/8.85k [00:00<00:00, 12.8MB/s]\nDownloading: 100%|██████████| 52.0k/52.0k [00:00<00:00, 1.47MB/s]\nDownloading: 100%|██████████| 29.6k/29.6k [00:00<00:00, 1.90MB/s]\n2024-05-21 08:04:45,604 - modelscope - INFO - initiate model from /root/.cache/modelscope/hub/damo/cv_convnextTiny_ocr-recognition-document_damo\n2024-05-21 08:04:45,605 - modelscope - INFO - initiate model from location /root/.cache/modelscope/hub/damo/cv_convnextTiny_ocr-recognition-document_damo.\n2024-05-21 08:04:45,607 - modelscope - INFO - initialize model from /root/.cache/modelscope/hub/damo/cv_convnextTiny_ocr-recognition-document_damo\n2024-05-21 08:04:45,920 - modelscope - INFO - loading model from dir /root/.cache/modelscope/hub/damo/cv_convnextTiny_ocr-recognition-document_damo\n2024-05-21 08:04:45,959 - modelscope - INFO - loading model done\n","output_type":"stream"}]},{"cell_type":"code","source":"doc = d.document_structure(\"../documents/purchasing_contract_example.pdf\")","metadata":{"id":"J75fo5UwqLMy","execution":{"iopub.status.busy":"2024-05-21T08:04:52.562937Z","iopub.execute_input":"2024-05-21T08:04:52.563294Z","iopub.status.idle":"2024-05-21T08:07:18.522232Z","shell.execute_reply.started":"2024-05-21T08:04:52.563268Z","shell.execute_reply":"2024-05-21T08:07:18.521348Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df = d.json2df(doc)","metadata":{"id":"lqYAjunosTDf","execution":{"iopub.status.busy":"2024-05-21T08:11:02.430721Z","iopub.execute_input":"2024-05-21T08:11:02.431448Z","iopub.status.idle":"2024-05-21T08:11:02.440007Z","shell.execute_reply.started":"2024-05-21T08:11:02.431414Z","shell.execute_reply":"2024-05-21T08:11:02.439106Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!mkdir tables\nd.extractTables(\"../documents/purchasing_contract_example.pdf\", df)","metadata":{"id":"U1EstjIftGze","execution":{"iopub.status.busy":"2024-05-21T08:11:04.069786Z","iopub.execute_input":"2024-05-21T08:11:04.070156Z","iopub.status.idle":"2024-05-21T08:11:07.875946Z","shell.execute_reply.started":"2024-05-21T08:11:04.070126Z","shell.execute_reply":"2024-05-21T08:11:07.874571Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'tables': File exists\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmkdir tables\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractTables\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../documents/purchasing_contract_example.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/kaggle/working/docxchain/docxchain/docxchain_po.py:239\u001b[0m, in \u001b[0;36mDocxChain_PO.extractTables\u001b[0;34m(self, pdf, df)\u001b[0m\n\u001b[1;32m    237\u001b[0m img \u001b[38;5;241m=\u001b[39m images[page]\n\u001b[1;32m    238\u001b[0m img \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;28mint\u001b[39m(region[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m:\u001b[38;5;28mint\u001b[39m(region[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m30\u001b[39m, :,:]\n\u001b[0;32m--> 239\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtables/table-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-page\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:2200\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave)\n\u001b[1;32m   2199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimsave\u001b[39m(fname, arr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1688\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1689\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:2432\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2429\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2432\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2433\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:637\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m im\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    636\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot write empty image as JPEG\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    640\u001b[0m     rawmode \u001b[38;5;241m=\u001b[39m RAWMODE[im\u001b[38;5;241m.\u001b[39mmode]\n","\u001b[0;31mValueError\u001b[0m: cannot write empty image as JPEG"],"ename":"ValueError","evalue":"cannot write empty image as JPEG","output_type":"error"}]},{"cell_type":"code","source":"df[df[\"category_name\"] == \"table\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:11:46.418367Z","iopub.execute_input":"2024-05-21T08:11:46.418757Z","iopub.status.idle":"2024-05-21T08:11:46.437544Z","shell.execute_reply.started":"2024-05-21T08:11:46.418726Z","shell.execute_reply":"2024-05-21T08:11:46.436134Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                          region category_name  \\\n58    [99, 978, 1563, 978, 1563, 1381, 99, 1381]         table   \n60  [92, 1485, 1558, 1485, 1558, 1857, 92, 1857]         table   \n64          [96, 44, 831, 44, 831, 648, 96, 648]         table   \n66  [101, 788, 1062, 788, 1062, 1372, 101, 1372]         table   \n77          [96, 8, 1552, 8, 1552, 194, 96, 194]         table   \n85      [96, 642, 1562, 642, 1562, 950, 96, 950]         table   \n89  [98, 1425, 1559, 1425, 1559, 1584, 98, 1585]         table   \n92    [99, 665, 1547, 665, 1547, 1473, 99, 1473]         table   \n98    [95, 736, 1554, 736, 1554, 1443, 95, 1444]         table   \n\n                                              content  page  \n58  Remise accordee (en %) sur le Nom du Package T...     2  \n60  N Nom du Produit ENOVIA V6 Trigramme Remise ac...     2  \n64  CATIA - MECHANICAL DESIGN 2 Configuration MD2 ...     3  \n66  CATIA - MECHANICAL DESIGN 2 Configuration mD2 ...     3  \n77  Montant net commandé (en euros H.T.) Remise ac...     4  \n85  Montant net commandé (en euros H.T.) Remise ac...     4  \n89  Production De 0 € à 93 999 € 17,5% Production ...     4  \n92  Portfolio Release Trigramme Nom du Produit Ref...     5  \n98  Portfolio Release Trigramme Nom du Produit Qua...     6  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region</th>\n      <th>category_name</th>\n      <th>content</th>\n      <th>page</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>58</th>\n      <td>[99, 978, 1563, 978, 1563, 1381, 99, 1381]</td>\n      <td>table</td>\n      <td>Remise accordee (en %) sur le Nom du Package T...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>[92, 1485, 1558, 1485, 1558, 1857, 92, 1857]</td>\n      <td>table</td>\n      <td>N Nom du Produit ENOVIA V6 Trigramme Remise ac...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>[96, 44, 831, 44, 831, 648, 96, 648]</td>\n      <td>table</td>\n      <td>CATIA - MECHANICAL DESIGN 2 Configuration MD2 ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>[101, 788, 1062, 788, 1062, 1372, 101, 1372]</td>\n      <td>table</td>\n      <td>CATIA - MECHANICAL DESIGN 2 Configuration mD2 ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>[96, 8, 1552, 8, 1552, 194, 96, 194]</td>\n      <td>table</td>\n      <td>Montant net commandé (en euros H.T.) Remise ac...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>[96, 642, 1562, 642, 1562, 950, 96, 950]</td>\n      <td>table</td>\n      <td>Montant net commandé (en euros H.T.) Remise ac...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>[98, 1425, 1559, 1425, 1559, 1584, 98, 1585]</td>\n      <td>table</td>\n      <td>Production De 0 € à 93 999 € 17,5% Production ...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>[99, 665, 1547, 665, 1547, 1473, 99, 1473]</td>\n      <td>table</td>\n      <td>Portfolio Release Trigramme Nom du Produit Ref...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>[95, 736, 1554, 736, 1554, 1443, 95, 1444]</td>\n      <td>table</td>\n      <td>Portfolio Release Trigramme Nom du Produit Qua...</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Challenge 2: Chuncking + embedding 🧮","metadata":{}},{"cell_type":"code","source":"from langchain.text_splitter import RecursiveCharacterTextSplitter\ntext_splitter = RecursiveCharacterTextSplitter(\n    # Set a really small chunk size, just to show.\n    chunk_size = 256,\n    chunk_overlap  = 20\n)","metadata":{"id":"5MO7aPqXwwUv","outputId":"0df7f13f-0326-4588-f56d-3981eacf5d25","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-05-21T08:12:11.525855Z","iopub.execute_input":"2024-05-21T08:12:11.526514Z","iopub.status.idle":"2024-05-21T08:12:11.838980Z","shell.execute_reply.started":"2024-05-21T08:12:11.526470Z","shell.execute_reply":"2024-05-21T08:12:11.838183Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"texts = []\nfor i in range(df.shape[0]):\n    if df.iloc[i][\"category_name\"] == \"plain text\" or df.iloc[i][\"category_name\"] == \"title\" or df.iloc[i][\"category_name\"] == \"header\" or df.iloc[i][\"category_name\"] == \"figure caption\" or df.iloc[i][\"category_name\"] == \"table caption\":\n        if \"unique appartenant au\" in df.iloc[i][\"content\"]:\n            print(df.iloc[i][\"content\"])\n        texts.append(df.iloc[i][\"content\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:12:15.917162Z","iopub.execute_input":"2024-05-21T08:12:15.917787Z","iopub.status.idle":"2024-05-21T08:12:15.951634Z","shell.execute_reply.started":"2024-05-21T08:12:15.917750Z","shell.execute_reply":"2024-05-21T08:12:15.950778Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"docs = text_splitter.create_documents(texts)","metadata":{"id":"BKD3BLzGtMAx","execution":{"iopub.status.busy":"2024-05-21T08:12:27.887620Z","iopub.execute_input":"2024-05-21T08:12:27.888559Z","iopub.status.idle":"2024-05-21T08:12:27.907965Z","shell.execute_reply.started":"2024-05-21T08:12:27.888521Z","shell.execute_reply":"2024-05-21T08:12:27.906961Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def chuncking(txt):\n    docs = text_splitter.create_documents(texts)\n    return pd.DataFrame([i.page_content for i in docs], columns=[\"chuncks\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:55:32.747536Z","iopub.execute_input":"2024-05-21T08:55:32.747926Z","iopub.status.idle":"2024-05-21T08:55:32.753043Z","shell.execute_reply.started":"2024-05-21T08:55:32.747896Z","shell.execute_reply":"2024-05-21T08:55:32.752085Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"chunks = chuncking(texts)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:55:35.341191Z","iopub.execute_input":"2024-05-21T08:55:35.342000Z","iopub.status.idle":"2024-05-21T08:55:35.360011Z","shell.execute_reply.started":"2024-05-21T08:55:35.341957Z","shell.execute_reply":"2024-05-21T08:55:35.358972Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nmodel =  SentenceTransformer(\"dangvantuan/sentence-camembert-large\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:55:36.348467Z","iopub.execute_input":"2024-05-21T08:55:36.349407Z","iopub.status.idle":"2024-05-21T08:55:37.967521Z","shell.execute_reply.started":"2024-05-21T08:55:36.349370Z","shell.execute_reply":"2024-05-21T08:55:37.966684Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def embedding(d):\n    e = model.encode(d[\"chuncks\"])\n    d[\"embeddings\"] = e.tolist()\n    return d","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:55:37.969426Z","iopub.execute_input":"2024-05-21T08:55:37.970129Z","iopub.status.idle":"2024-05-21T08:55:37.975157Z","shell.execute_reply.started":"2024-05-21T08:55:37.970091Z","shell.execute_reply":"2024-05-21T08:55:37.974120Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"chunks = embedding(chunks)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:55:42.431419Z","iopub.execute_input":"2024-05-21T08:55:42.431913Z","iopub.status.idle":"2024-05-21T08:55:43.469598Z","shell.execute_reply.started":"2024-05-21T08:55:42.431877Z","shell.execute_reply":"2024-05-21T08:55:43.468786Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c0f7cd61462421b8b1a71b4154f117f"}},"metadata":{}}]},{"cell_type":"code","source":"chunks","metadata":{"execution":{"iopub.status.busy":"2024-05-21T08:55:44.435355Z","iopub.execute_input":"2024-05-21T08:55:44.435837Z","iopub.status.idle":"2024-05-21T08:55:44.460033Z","shell.execute_reply.started":"2024-05-21T08:55:44.435804Z","shell.execute_reply":"2024-05-21T08:55:44.458984Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"                                               chuncks  \\\n0                         AVENANT N°5 (ref 2021-15874)   \n1    AU CONTRAT CADRE CLIENT DE LICENCE ET DE SERVI...   \n2    Le present avenant (c-apres,I‘w Avenant N\"5 ) ...   \n3    europenme de droi fancais, dont e siege socale...   \n4    dont le siege social est sis 19 Boulevard Jule...   \n..                                                 ...   \n172                                4.7. Cession par DS   \n173  L'article 14.10 des Conditions Générales est m...   \n174  14.10. DS e resenve le droit de ceder, deleque...   \n175         tout tiers, sans le consentement du Client   \n176                     FIN DES CONDITIONS SPECIFIQUES   \n\n                                            embeddings  \n0    [-0.3560839295387268, -0.34902799129486084, 0....  \n1    [0.17224104702472687, 0.18271885812282562, 0.1...  \n2    [-0.02520272135734558, -0.26985621452331543, 0...  \n3    [0.10028597712516785, -0.0003191527212038636, ...  \n4    [0.03617846220731735, -0.046792007982730865, -...  \n..                                                 ...  \n172  [0.035654980689287186, 0.12960749864578247, 0....  \n173  [-0.5745832324028015, -0.4059491753578186, -0....  \n174  [-0.2994324266910553, -0.06207720562815666, 0....  \n175  [-0.41874009370803833, 0.22491231560707092, -0...  \n176  [-0.6323919296264648, 0.07268539071083069, -0....  \n\n[177 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chuncks</th>\n      <th>embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AVENANT N°5 (ref 2021-15874)</td>\n      <td>[-0.3560839295387268, -0.34902799129486084, 0....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AU CONTRAT CADRE CLIENT DE LICENCE ET DE SERVI...</td>\n      <td>[0.17224104702472687, 0.18271885812282562, 0.1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Le present avenant (c-apres,I‘w Avenant N\"5 ) ...</td>\n      <td>[-0.02520272135734558, -0.26985621452331543, 0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>europenme de droi fancais, dont e siege socale...</td>\n      <td>[0.10028597712516785, -0.0003191527212038636, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dont le siege social est sis 19 Boulevard Jule...</td>\n      <td>[0.03617846220731735, -0.046792007982730865, -...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>4.7. Cession par DS</td>\n      <td>[0.035654980689287186, 0.12960749864578247, 0....</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>L'article 14.10 des Conditions Générales est m...</td>\n      <td>[-0.5745832324028015, -0.4059491753578186, -0....</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>14.10. DS e resenve le droit de ceder, deleque...</td>\n      <td>[-0.2994324266910553, -0.06207720562815666, 0....</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>tout tiers, sans le consentement du Client</td>\n      <td>[-0.41874009370803833, 0.22491231560707092, -0...</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>FIN DES CONDITIONS SPECIFIQUES</td>\n      <td>[-0.6323919296264648, 0.07268539071083069, -0....</td>\n    </tr>\n  </tbody>\n</table>\n<p>177 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Challenge 3: Vector db 💾","metadata":{}},{"cell_type":"code","source":"import chromadb\nchroma_client = chromadb.Client()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:10:24.588153Z","iopub.execute_input":"2024-05-21T09:10:24.588894Z","iopub.status.idle":"2024-05-21T09:10:25.973452Z","shell.execute_reply.started":"2024-05-21T09:10:24.588855Z","shell.execute_reply":"2024-05-21T09:10:25.972682Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"collection = chroma_client.create_collection(name=\"contract_example\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T09:10:57.420918Z","iopub.execute_input":"2024-05-21T09:10:57.421297Z","iopub.status.idle":"2024-05-21T09:10:57.445239Z","shell.execute_reply.started":"2024-05-21T09:10:57.421267Z","shell.execute_reply":"2024-05-21T09:10:57.444504Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}